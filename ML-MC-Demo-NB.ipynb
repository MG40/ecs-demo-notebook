{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","\n","import boto3, re, sys, math, json, os, sagemaker, urllib.request\n","import sagemaker\n","from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n","from sagemaker.session import TrainingInput\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import Image\n","from IPython.display import display\n","from time import gmtime, strftime\n","\n","# Display AWS Region, IAM Role used by the SageMaker and SageMaker Image URI\n","\n","region = sagemaker.Session().boto_region_name\n","print(\"AWS Region: {}\".format(region))\n","\n","role = sagemaker.get_execution_role()\n","print(\"RoleArn: {}\".format(role))\n","\n","container=sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n","print(\"SageMaker Image:{}\".format(container))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load environment variables\n","\n","!pip install python-dotenv\n","%load_ext dotenv\n","%dotenv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating a bucket in the ECS \n","\n","bucket_name = 'bucket_name' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n","ecs_access_key_id=os.environ['ECS_ACCESS_KEY_ID']  # <--- Environment variable for ECS Access Key\n","ecs_secret_access_key=os.environ['ECS_SECRET_ACCESS_KEY'] # <--- Environment variable for Secret Access Key\n","endpoint_url='https://1.2.3.4:5678' # <--- Replace this variable with the IP Address and Port number\n","s3 = boto3.resource(service_name='s3',aws_access_key_id=ecs_access_key_id,aws_secret_access_key=ecs_secret_access_key,endpoint_url=endpoint_url)\n","try:\n","    s3.create_bucket(Bucket=bucket_name)\n","    print('S3 bucket created successfully')\n","except Exception as e:\n","    print('S3 error: ',e)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download csv to train\n","try:\n","  urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n","  print('Success: downloaded bank_clean.csv.')\n","except Exception as e:\n","  print('Data load error: ',e)\n","\n","try:\n","  model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n","  print('Success: Data loaded into dataframe.')\n","except Exception as e:\n","    print('Data load error: ',e)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train data step\n","train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n","print(train_data.shape, test_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train data step\n","pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Upload file to ECS bucket with \"upload_\" prefix\n","s3=boto3.resource(service_name='s3',aws_access_key_id=ecs_access_key_id,aws_secret_access_key=ecs_secret_access_key,endpoint_url=endpoint_url)\n","s3_data=s3.Bucket(bucket_name).Object(os.path.join('train/upload_train.csv')).upload_file('train.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download file from ECS bucket\n","s3_ddata=s3.Bucket(bucket_name).Object(os.path.join('train/upload_train.csv')).download_file('download_train.csv')\n","\n","# Check in the terminal for downloaded file\n","# You should be able to see download_train.csv and train.csv"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
